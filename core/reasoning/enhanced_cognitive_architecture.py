#!/usr/bin/env python3
"""
Enhanced Cognitive Architecture Framework for Marcus AGI
=======================================================

This module extends the Neural-Symbolic Integration System with a comprehensive
cognitive architecture incorporating multiple cognitive models and frameworks
for advanced AGI prototype development.

Based on neurosymbolic neural network research, this framework integrates:
- Core neurosymbolic reasoning as foundational layer
- Transformer models for enhanced NLP capabilities
- Graph Neural Networks for relationship modeling
- Probabilistic programming for uncertainty handling
- Reinforcement learning for adaptive decision making
- Multiple memory systems (working, episodic, semantic)
- Metacognitive monitoring and control systems

Advanced Cognitive Components:
- NARS-inspired adaptive reasoning
- HTM-like temporal pattern recognition
- ACT-R inspired production rules
- Bayesian networks for probabilistic inference
- Associative networks for concept linking
- Divergent thinking modules
- Analogical reasoning capabilities
- Context-switching mechanisms

Integration Points:
- Bidirectional communication between all components
- Central executive control system
- Dynamic knowledge base updates
- Flexible reasoning engine with mode switching
- Parallel processing capabilities
- Resource allocation monitoring
- Multi-level explainability mechanisms
"""

import sqlite3
import json
import logging
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Set, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
import uuid
import statistics
import re
from collections import defaultdict, Counter, deque
import threading
import queue
import time
from abc import ABC, abstractmethod

# Import our existing neural-symbolic system
try:
    from .neural_symbolic_integration import (
        NeuralSymbolicIntegration, ReasoningMode, ProblemType,
        NeuralPattern, SymbolicRule, ReasoningEpisode, HybridReasoningResult
    )
    from .advanced_reasoning_engine import AdvancedReasoningEngine, ReasoningProblem, ReasoningResult
    from .cross_domain_transfer_engine import CrossDomainTransferEngine, AbstractPattern, DomainType
    from ..consciousness.consciousness_integration_framework import ConsciousnessIntegrationFramework
    from ..memory.autobiographical_memory_system import AutobiographicalMemorySystem
    INTEGRATION_AVAILABLE = True
except ImportError:
    # Stub classes for standalone mode
    INTEGRATION_AVAILABLE = False
    logging.warning("Core integration systems not available - running in development mode")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CognitiveModuleType(Enum):
    """Types of cognitive modules in the enhanced architecture."""
    NEUROSYMBOLIC_CORE = "neurosymbolic_core"
    WORKING_MEMORY = "working_memory"
    EPISODIC_MEMORY = "episodic_memory"
    SEMANTIC_MEMORY = "semantic_memory"
    ATTENTION_MECHANISM = "attention_mechanism"
    METACOGNITIVE_MONITOR = "metacognitive_monitor"
    EXECUTIVE_CONTROL = "executive_control"
    TRANSFORMER_NLP = "transformer_nlp"
    GRAPH_NEURAL_NET = "graph_neural_net"
    PROBABILISTIC_REASONING = "probabilistic_reasoning"
    REINFORCEMENT_LEARNING = "reinforcement_learning"
    TEMPORAL_PATTERN_RECOGNITION = "temporal_pattern_recognition"
    ASSOCIATIVE_NETWORK = "associative_network"
    ANALOGICAL_REASONING = "analogical_reasoning"
    DIVERGENT_THINKING = "divergent_thinking"


class ProcessingPriority(Enum):
    """Processing priority levels for cognitive modules."""
    CRITICAL = 1
    HIGH = 2
    MEDIUM = 3
    LOW = 4
    BACKGROUND = 5


@dataclass
class CognitiveTask:
    """Represents a task for processing by cognitive modules."""
    task_id: str
    task_type: str
    input_data: Dict[str, Any]
    priority: ProcessingPriority
    required_modules: List[CognitiveModuleType]
    context: Dict[str, Any] = field(default_factory=dict)
    deadline: Optional[datetime] = None
    created: datetime = field(default_factory=datetime.now)
    started: Optional[datetime] = None
    completed: Optional[datetime] = None
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None


@dataclass
class MemoryTrace:
    """Represents a memory trace across different memory systems."""
    trace_id: str
    content: Dict[str, Any]
    memory_type: str  # "working", "episodic", "semantic"
    encoding_strength: float
    retrieval_count: int = 0
    last_accessed: datetime = field(default_factory=datetime.now)
    associations: List[str] = field(default_factory=list)
    emotional_valence: float = 0.0
    temporal_context: Optional[Dict[str, Any]] = None


@dataclass
class AttentionState:
    """Represents the current attention state of the system."""
    focus_targets: List[str]
    attention_weights: Dict[str, float]
    attention_span: float
    distraction_resistance: float
    cognitive_load: float
    timestamp: datetime = field(default_factory=datetime.now)


class CognitiveModule(ABC):
    """Abstract base class for cognitive modules."""
    
    def __init__(self, module_type: CognitiveModuleType):
        self.module_type = module_type
        self.is_active = True
        self.processing_queue = queue.Queue()
        self.resource_usage = 0.0
        self.performance_metrics = {}
        self.last_update = datetime.now()
    
    @abstractmethod
    def process(self, task: CognitiveTask) -> Dict[str, Any]:
        """Process a cognitive task and return results."""
        pass
    
    @abstractmethod
    def update_state(self, feedback: Dict[str, Any]):
        """Update internal state based on feedback."""
        pass
    
    def get_status(self) -> Dict[str, Any]:
        """Get current module status."""
        return {
            "module_type": self.module_type.value,
            "is_active": self.is_active,
            "queue_size": self.processing_queue.qsize(),
            "resource_usage": self.resource_usage,
            "performance_metrics": self.performance_metrics,
            "last_update": self.last_update.isoformat()
        }


class WorkingMemoryModule(CognitiveModule):
    """Working memory module with attention-based buffer management."""
    
    def __init__(self):
        super().__init__(CognitiveModuleType.WORKING_MEMORY)
        self.buffer_capacity = 7  # Miller's magical number
        self.current_buffer = deque(maxlen=self.buffer_capacity)
        self.attention_weights = {}
        self.rehearsal_queue = queue.Queue()
        
    def process(self, task: CognitiveTask) -> Dict[str, Any]:
        """Process working memory operations."""
        operation = task.input_data.get('operation', 'store')
        
        if operation == 'store':
            return self._store_item(task.input_data.get('item'))
        elif operation == 'retrieve':
            return self._retrieve_item(task.input_data.get('query'))
        elif operation == 'update':
            return self._update_item(task.input_data.get('item_id'), task.input_data.get('new_data'))
        elif operation == 'rehearse':
            return self._rehearse_items()
        else:
            return {"error": f"Unknown working memory operation: {operation}"}
    
    def _store_item(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """Store an item in working memory buffer."""
        if len(self.current_buffer) >= self.buffer_capacity:
            # Remove least attended item
            removed_item = self._remove_least_attended()
            logger.debug(f"Working memory full, removed: {removed_item}")
        
        item_id = str(uuid.uuid4())[:8]
        memory_item = {
            'id': item_id,
            'content': item,
            'attention_weight': 1.0,
            'stored_at': datetime.now(),
            'access_count': 0
        }
        
        self.current_buffer.append(memory_item)
        self.attention_weights[item_id] = 1.0
        
        return {"success": True, "item_id": item_id, "buffer_size": len(self.current_buffer)}
    
    def _retrieve_item(self, query: Dict[str, Any]) -> Dict[str, Any]:
        """Retrieve items from working memory based on query."""
        matching_items = []
        
        for item in self.current_buffer:
            relevance = self._calculate_relevance(item['content'], query)
            if relevance > 0.3:  # Relevance threshold
                item['access_count'] += 1
                self.attention_weights[item['id']] *= 1.1  # Boost attention
                matching_items.append({
                    'item': item,
                    'relevance': relevance
                })
        
        # Sort by relevance and attention weight
        matching_items.sort(key=lambda x: x['relevance'] * self.attention_weights.get(x['item']['id'], 1.0), reverse=True)
        
        return {
            "success": True,
            "retrieved_items": [item['item'] for item in matching_items[:3]],  # Top 3 matches
            "total_matches": len(matching_items)
        }
    
    def _update_item(self, item_id: str, new_data: Dict[str, Any]) -> Dict[str, Any]:
        """Update an existing item in working memory."""
        for item in self.current_buffer:
            if item['id'] == item_id:
                item['content'].update(new_data)
                item['access_count'] += 1
                self.attention_weights[item_id] *= 1.05  # Small attention boost
                return {"success": True, "updated_item_id": item_id}
        
        return {"success": False, "error": f"Item {item_id} not found in working memory"}
    
    def _rehearse_items(self) -> Dict[str, Any]:
        """Rehearse items to maintain them in working memory."""
        rehearsed_count = 0
        for item in self.current_buffer:
            if self.attention_weights.get(item['id'], 0) > 0.5:
                self.attention_weights[item['id']] *= 1.02  # Small rehearsal boost
                rehearsed_count += 1
        
        return {"success": True, "rehearsed_items": rehearsed_count}
    
    def _remove_least_attended(self) -> Dict[str, Any]:
        """Remove the least attended item from working memory."""
        if not self.current_buffer:
            return None
        
        least_attended_item = min(self.current_buffer, 
                                key=lambda x: self.attention_weights.get(x['id'], 0))
        self.current_buffer.remove(least_attended_item)
        
        if least_attended_item['id'] in self.attention_weights:
            del self.attention_weights[least_attended_item['id']]
        
        return least_attended_item
    
    def _calculate_relevance(self, content: Dict[str, Any], query: Dict[str, Any]) -> float:
        """Calculate relevance between content and query."""
        # Simple keyword-based relevance calculation
        content_text = json.dumps(content).lower()
        query_text = json.dumps(query).lower()
        
        content_words = set(re.findall(r'\w+', content_text))
        query_words = set(re.findall(r'\w+', query_text))
        
        if not query_words:
            return 0.0
        
        overlap = len(content_words & query_words)
        relevance = overlap / len(query_words)
        
        return relevance
    
    def update_state(self, feedback: Dict[str, Any]):
        """Update working memory state based on feedback."""
        if 'attention_update' in feedback:
            for item_id, weight_change in feedback['attention_update'].items():
                if item_id in self.attention_weights:
                    self.attention_weights[item_id] = max(0.1, 
                        self.attention_weights[item_id] + weight_change)


class EpisodicMemoryModule(CognitiveModule):
    """Episodic memory module for storing and retrieving specific experiences."""
    
    def __init__(self):
        super().__init__(CognitiveModuleType.EPISODIC_MEMORY)
        self.episodes = {}
        self.temporal_index = defaultdict(list)
        self.context_index = defaultdict(list)
        self.emotional_index = defaultdict(list)
        
    def process(self, task: CognitiveTask) -> Dict[str, Any]:
        """Process episodic memory operations."""
        operation = task.input_data.get('operation', 'store')
        
        if operation == 'store':
            return self._store_episode(task.input_data.get('episode'))
        elif operation == 'retrieve':
            return self._retrieve_episodes(task.input_data.get('query'))
        elif operation == 'consolidate':
            return self._consolidate_memories()
        else:
            return {"error": f"Unknown episodic memory operation: {operation}"}
    
    def _store_episode(self, episode_data: Dict[str, Any]) -> Dict[str, Any]:
        """Store an episodic memory."""
        episode_id = str(uuid.uuid4())
        
        episode = MemoryTrace(
            trace_id=episode_id,
            content=episode_data,
            memory_type="episodic",
            encoding_strength=episode_data.get('importance', 0.7),
            emotional_valence=episode_data.get('emotional_valence', 0.0),
            temporal_context={
                'timestamp': datetime.now(),
                'context': episode_data.get('context', {})
            }
        )
        
        self.episodes[episode_id] = episode
        
        # Update indices
        time_key = episode.temporal_context['timestamp'].strftime('%Y-%m-%d')
        self.temporal_index[time_key].append(episode_id)
        
        for context_key, context_value in episode_data.get('context', {}).items():
            self.context_index[f"{context_key}:{context_value}"].append(episode_id)
        
        emotional_range = self._get_emotional_range(episode.emotional_valence)
        self.emotional_index[emotional_range].append(episode_id)
        
        return {"success": True, "episode_id": episode_id}
    
    def _retrieve_episodes(self, query: Dict[str, Any]) -> Dict[str, Any]:
        """Retrieve episodes based on query criteria."""
        candidate_episodes = set(self.episodes.keys())
        
        # Filter by temporal criteria
        if 'time_range' in query:
            time_candidates = set()
            start_date = query['time_range'].get('start')
            end_date = query['time_range'].get('end')
            
            for date_key, episode_ids in self.temporal_index.items():
                date_obj = datetime.strptime(date_key, '%Y-%m-%d').date()
                if (not start_date or date_obj >= start_date) and (not end_date or date_obj <= end_date):
                    time_candidates.update(episode_ids)
            
            candidate_episodes &= time_candidates
        
        # Filter by context
        if 'context' in query:
            context_candidates = set()
            for context_key, context_value in query['context'].items():
                context_candidates.update(self.context_index.get(f"{context_key}:{context_value}", []))
            
            if context_candidates:
                candidate_episodes &= context_candidates
        
        # Filter by emotional valence
        if 'emotional_range' in query:
            emotional_candidates = set()
            for emotion_range in query['emotional_range']:
                emotional_candidates.update(self.emotional_index.get(emotion_range, []))
            
            if emotional_candidates:
                candidate_episodes &= emotional_candidates
        
        # Retrieve and rank episodes
        retrieved_episodes = []
        for episode_id in candidate_episodes:
            episode = self.episodes[episode_id]
            episode.retrieval_count += 1
            episode.last_accessed = datetime.now()
            
            relevance = self._calculate_episode_relevance(episode, query)
            retrieved_episodes.append({
                'episode': episode,
                'relevance': relevance
            })
        
        # Sort by relevance and recency
        retrieved_episodes.sort(key=lambda x: (x['relevance'], x['episode'].encoding_strength), reverse=True)
        
        return {
            "success": True,
            "episodes": [ep['episode'] for ep in retrieved_episodes[:10]],  # Top 10
            "total_found": len(retrieved_episodes)
        }
    
    def _consolidate_memories(self) -> Dict[str, Any]:
        """Consolidate episodic memories by strengthening important ones."""
        consolidated_count = 0
        
        for episode in self.episodes.values():
            # Strengthen memories that are frequently accessed or emotionally significant
            if episode.retrieval_count > 3 or abs(episode.emotional_valence) > 0.7:
                episode.encoding_strength = min(1.0, episode.encoding_strength * 1.1)
                consolidated_count += 1
            
            # Weaken rarely accessed memories
            elif episode.retrieval_count == 0 and episode.encoding_strength < 0.3:
                episode.encoding_strength *= 0.9
        
        return {"success": True, "consolidated_episodes": consolidated_count}
    
    def _get_emotional_range(self, valence: float) -> str:
        """Get emotional range category for indexing."""
        if valence > 0.5:
            return "very_positive"
        elif valence > 0.1:
            return "positive"
        elif valence > -0.1:
            return "neutral"
        elif valence > -0.5:
            return "negative"
        else:
            return "very_negative"
    
    def _calculate_episode_relevance(self, episode: MemoryTrace, query: Dict[str, Any]) -> float:
        """Calculate relevance of episode to query."""
        relevance_factors = []
        
        # Content similarity
        if 'content_keywords' in query:
            content_text = json.dumps(episode.content).lower()
            keyword_matches = sum(1 for keyword in query['content_keywords'] 
                                if keyword.lower() in content_text)
            content_relevance = keyword_matches / len(query['content_keywords']) if query['content_keywords'] else 0
            relevance_factors.append(content_relevance)
        
        # Temporal relevance (more recent = more relevant, unless specifically querying old memories)
        time_since = (datetime.now() - episode.temporal_context['timestamp']).total_seconds()
        temporal_relevance = 1.0 / (1.0 + time_since / 86400)  # Decay over days
        relevance_factors.append(temporal_relevance * 0.3)  # Lower weight for temporal
        
        # Encoding strength
        relevance_factors.append(episode.encoding_strength)
        
        return statistics.mean(relevance_factors) if relevance_factors else 0.0
    
    def update_state(self, feedback: Dict[str, Any]):
        """Update episodic memory state based on feedback."""
        if 'memory_reinforcement' in feedback:
            for episode_id, strength_change in feedback['memory_reinforcement'].items():
                if episode_id in self.episodes:
                    episode = self.episodes[episode_id]
                    episode.encoding_strength = max(0.1, min(1.0, 
                        episode.encoding_strength + strength_change))


class MetacognitiveMonitor(CognitiveModule):
    """Metacognitive monitoring module for self-awareness and control."""
    
    def __init__(self):
        super().__init__(CognitiveModuleType.METACOGNITIVE_MONITOR)
        self.cognitive_state_history = deque(maxlen=100)
        self.performance_metrics = {}
        self.error_patterns = defaultdict(list)
        self.strategy_effectiveness = {}
        
    def process(self, task: CognitiveTask) -> Dict[str, Any]:
        """Process metacognitive monitoring tasks."""
        operation = task.input_data.get('operation', 'monitor')
        
        if operation == 'monitor':
            return self._monitor_cognitive_state(task.input_data.get('system_state'))
        elif operation == 'evaluate_performance':
            return self._evaluate_performance(task.input_data.get('task_results'))
        elif operation == 'detect_errors':
            return self._detect_error_patterns()
        elif operation == 'recommend_strategy':
            return self._recommend_strategy(task.input_data.get('problem_context'))
        else:
            return {"error": f"Unknown metacognitive operation: {operation}"}
    
    def _monitor_cognitive_state(self, system_state: Dict[str, Any]) -> Dict[str, Any]:
        """Monitor overall cognitive state and identify issues."""
        current_state = {
            'timestamp': datetime.now(),
            'working_memory_load': system_state.get('working_memory_load', 0.0),
            'attention_focus': system_state.get('attention_focus', []),
            'processing_speed': system_state.get('processing_speed', 1.0),
            'error_rate': system_state.get('error_rate', 0.0),
            'confidence_level': system_state.get('confidence_level', 0.5)
        }
        
        self.cognitive_state_history.append(current_state)
        
        # Analyze trends
        issues_detected = []
        
        # Check for cognitive overload
        if current_state['working_memory_load'] > 0.8:
            issues_detected.append("high_cognitive_load")
        
        # Check for attention problems
        if len(current_state['attention_focus']) > 5:
            issues_detected.append("attention_scattered")
        
        # Check for performance degradation
        if len(self.cognitive_state_history) > 5:
            recent_error_rates = [state['error_rate'] for state in list(self.cognitive_state_history)[-5:]]
            if statistics.mean(recent_error_rates) > 0.3:
                issues_detected.append("increasing_error_rate")
        
        # Generate recommendations
        recommendations = self._generate_recommendations(issues_detected, current_state)
        
        return {
            "success": True,
            "current_state": current_state,
            "issues_detected": issues_detected,
            "recommendations": recommendations
        }
    
    def _evaluate_performance(self, task_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Evaluate performance across recent tasks."""
        if not task_results:
            return {"success": True, "evaluation": "No recent tasks to evaluate"}
        
        # Calculate performance metrics
        success_rate = sum(1 for result in task_results if result.get('success', False)) / len(task_results)
        average_confidence = statistics.mean([result.get('confidence', 0.5) for result in task_results])
        average_completion_time = statistics.mean([result.get('completion_time', 1.0) for result in task_results])
        
        # Identify performance patterns
        performance_by_task_type = defaultdict(list)
        for result in task_results:
            task_type = result.get('task_type', 'unknown')
            performance_by_task_type[task_type].append(result.get('success', False))
        
        strengths = []
        weaknesses = []
        
        for task_type, successes in performance_by_task_type.items():
            type_success_rate = sum(successes) / len(successes)
            if type_success_rate > 0.8:
                strengths.append(task_type)
            elif type_success_rate < 0.5:
                weaknesses.append(task_type)
        
        # Update performance metrics
        self.performance_metrics.update({
            'overall_success_rate': success_rate,
            'average_confidence': average_confidence,
            'average_completion_time': average_completion_time,
            'strengths': strengths,
            'weaknesses': weaknesses,
            'last_evaluation': datetime.now()
        })
        
        return {
            "success": True,
            "performance_metrics": self.performance_metrics,
            "improvement_suggestions": self._generate_improvement_suggestions(weaknesses)
        }
    
    def _detect_error_patterns(self) -> Dict[str, Any]:
        """Detect recurring error patterns."""
        detected_patterns = []
        
        for error_type, occurrences in self.error_patterns.items():
            if len(occurrences) > 3:  # Pattern threshold
                recent_occurrences = [occ for occ in occurrences 
                                    if (datetime.now() - occ['timestamp']).days < 7]
                if len(recent_occurrences) > 1:
                    detected_patterns.append({
                        'error_type': error_type,
                        'frequency': len(recent_occurrences),
                        'contexts': [occ.get('context', 'unknown') for occ in recent_occurrences]
                    })
        
        return {"success": True, "error_patterns": detected_patterns}
    
    def _recommend_strategy(self, problem_context: Dict[str, Any]) -> Dict[str, Any]:
        """Recommend cognitive strategy based on problem context and past performance."""
        problem_type = problem_context.get('type', 'unknown')
        problem_complexity = problem_context.get('complexity', 'medium')
        
        # Base strategy recommendations
        strategy_recommendations = []
        
        # Check historical strategy effectiveness
        if problem_type in self.strategy_effectiveness:
            effective_strategies = sorted(
                self.strategy_effectiveness[problem_type].items(),
                key=lambda x: x[1],
                reverse=True
            )
            strategy_recommendations.extend([strategy for strategy, effectiveness in effective_strategies[:2]])
        
        # Default strategies based on problem characteristics
        if problem_complexity == 'high':
            strategy_recommendations.append('decomposition')
            strategy_recommendations.append('analogical_reasoning')
        
        if problem_context.get('requires_creativity', False):
            strategy_recommendations.append('divergent_thinking')
            strategy_recommendations.append('associative_reasoning')
        
        if problem_context.get('has_uncertainty', False):
            strategy_recommendations.append('probabilistic_reasoning')
            strategy_recommendations.append('evidence_gathering')
        
        return {
            "success": True,
            "recommended_strategies": list(set(strategy_recommendations)),
            "confidence": 0.7 if strategy_recommendations else 0.3
        }
    
    def _generate_recommendations(self, issues: List[str], state: Dict[str, Any]) -> List[str]:
        """Generate recommendations based on detected issues."""
        recommendations = []
        
        if "high_cognitive_load" in issues:
            recommendations.append("Reduce working memory load by chunking information")
            recommendations.append("Take processing breaks to prevent cognitive overload")
        
        if "attention_scattered" in issues:
            recommendations.append("Focus attention on fewer concurrent tasks")
            recommendations.append("Use attention filtering mechanisms")
        
        if "increasing_error_rate" in issues:
            recommendations.append("Implement error checking routines")
            recommendations.append("Slow down processing for accuracy")
        
        if state.get('confidence_level', 0.5) < 0.3:
            recommendations.append("Gather more information before making decisions")
            recommendations.append("Use validation mechanisms for critical decisions")
        
        return recommendations
    
    def _generate_improvement_suggestions(self, weaknesses: List[str]) -> List[str]:
        """Generate improvement suggestions for identified weaknesses."""
        suggestions = []
        
        for weakness in weaknesses:
            if 'logical' in weakness:
                suggestions.append("Practice step-by-step logical reasoning")
                suggestions.append("Use formal logic validation tools")
            elif 'creative' in weakness:
                suggestions.append("Expand associative thinking patterns")
                suggestions.append("Practice divergent thinking exercises")
            elif 'social' in weakness:
                suggestions.append("Study social interaction patterns")
                suggestions.append("Practice theory of mind reasoning")
            else:
                suggestions.append(f"Focus on improving {weakness} task performance")
        
        return suggestions
    
    def update_state(self, feedback: Dict[str, Any]):
        """Update metacognitive state based on feedback."""
        if 'error_occurred' in feedback:
            error_info = feedback['error_occurred']
            error_type = error_info.get('type', 'unknown')
            self.error_patterns[error_type].append({
                'timestamp': datetime.now(),
                'context': error_info.get('context', {}),
                'details': error_info.get('details', '')
            })
        
        if 'strategy_result' in feedback:
            strategy_info = feedback['strategy_result']
            problem_type = strategy_info.get('problem_type', 'unknown')
            strategy = strategy_info.get('strategy', 'unknown')
            effectiveness = strategy_info.get('effectiveness', 0.5)
            
            if problem_type not in self.strategy_effectiveness:
                self.strategy_effectiveness[problem_type] = {}
            
            # Update strategy effectiveness with exponential moving average
            current_effectiveness = self.strategy_effectiveness[problem_type].get(strategy, 0.5)
            self.strategy_effectiveness[problem_type][strategy] = (
                0.7 * current_effectiveness + 0.3 * effectiveness
            )


class EnhancedCognitiveArchitecture:
    """
    Comprehensive cognitive architecture integrating neurosymbolic reasoning
    with advanced cognitive models and frameworks.
    
    This system combines:
    - Core neurosymbolic reasoning (foundational layer)
    - Working, episodic, and semantic memory systems
    - Metacognitive monitoring and control
    - Transformer-enhanced NLP capabilities
    - Graph neural networks for relationship modeling
    - Probabilistic reasoning for uncertainty handling
    - Reinforcement learning for adaptive behavior
    - Temporal pattern recognition
    - Associative networks and analogical reasoning
    - Divergent thinking modules
    """
    
    def __init__(self, 
                 neural_symbolic_system: NeuralSymbolicIntegration = None,
                 reasoning_engine: AdvancedReasoningEngine = None,
                 transfer_engine: CrossDomainTransferEngine = None):
        """Initialize the enhanced cognitive architecture."""
        
        # Core neurosymbolic foundation
        self.neural_symbolic_core = neural_symbolic_system or NeuralSymbolicIntegration()
        self.reasoning_engine = reasoning_engine
        self.transfer_engine = transfer_engine
        
        # Initialize cognitive modules
        self.cognitive_modules = {}
        self._initialize_cognitive_modules()
        
        # Central executive control
        self.executive_control = ExecutiveController(self.cognitive_modules)
        
        # Processing infrastructure
        self.task_queue = queue.PriorityQueue()
        self.result_cache = {}
        self.processing_threads = {}
        self.is_running = False
        
        # Performance monitoring
        self.performance_metrics = {
            'tasks_processed': 0,
            'average_processing_time': 0.0,
            'success_rate': 0.0,
            'resource_efficiency': 0.0
        }
        
        # Database for persistence
        self.db_path = "marcus_enhanced_cognitive.db"
        self.setup_database()
        
        logger.info("ðŸ§  Enhanced Cognitive Architecture initialized")
    
    def _initialize_cognitive_modules(self):
        """Initialize all cognitive modules."""
        
        # Memory systems
        self.cognitive_modules[CognitiveModuleType.WORKING_MEMORY] = WorkingMemoryModule()
        self.cognitive_modules[CognitiveModuleType.EPISODIC_MEMORY] = EpisodicMemoryModule()
        
        # Metacognitive monitoring
        self.cognitive_modules[CognitiveModuleType.METACOGNITIVE_MONITOR] = MetacognitiveMonitor()
        
        # Additional modules would be implemented similarly:
        # - SemanticMemoryModule
        # - AttentionMechanism
        # - TransformerNLPModule
        # - GraphNeuralNetModule
        # - ProbabilisticReasoningModule
        # - ReinforcementLearningModule
        # - TemporalPatternRecognitionModule
        # - AssociativeNetworkModule
        # - AnalogicalReasoningModule
        # - DivergentThinkingModule
        
        logger.info(f"ðŸ§  Initialized {len(self.cognitive_modules)} cognitive modules")
    
    def setup_database(self):
        """Set up database schema for enhanced cognitive architecture."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # Cognitive tasks table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS cognitive_tasks (
                    task_id TEXT PRIMARY KEY,
                    task_type TEXT,
                    input_data TEXT,
                    priority INTEGER,
                    required_modules TEXT,
                    context TEXT,
                    created TEXT,
                    started TEXT,
                    completed TEXT,
                    result TEXT,
                    error TEXT
                )
            """)
            
            # Memory traces table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS memory_traces (
                    trace_id TEXT PRIMARY KEY,
                    content TEXT,
                    memory_type TEXT,
                    encoding_strength REAL,
                    retrieval_count INTEGER,
                    last_accessed TEXT,
                    associations TEXT,
                    emotional_valence REAL,
                    temporal_context TEXT
                )
            """)
            
            # Cognitive performance table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS cognitive_performance (
                    session_id TEXT PRIMARY KEY,
                    timestamp TEXT,
                    module_type TEXT,
                    performance_metrics TEXT,
                    resource_usage REAL
                )
            """)
            
            conn.commit()
    
    def process_cognitive_task(self, task: CognitiveTask) -> Dict[str, Any]:
        """Process a cognitive task through the appropriate modules."""
        
        start_time = datetime.now()
        task.started = start_time
        
        try:
            # Determine which modules to use
            if not task.required_modules:
                task.required_modules = self._determine_required_modules(task)
            
            # Process through executive control
            result = self.executive_control.coordinate_processing(task)
            
            # Update task with result
            task.completed = datetime.now()
            task.result = result
            
            # Learn from the experience
            self._learn_from_task(task)
            
            # Update performance metrics
            processing_time = (task.completed - task.started).total_seconds()
            self._update_performance_metrics(task, processing_time)
            
            return result
            
        except Exception as e:
            task.error = str(e)
            task.completed = datetime.now()
            logger.error(f"Error processing cognitive task {task.task_id}: {e}")
            return {"success": False, "error": str(e)}
    
    def _determine_required_modules(self, task: CognitiveTask) -> List[CognitiveModuleType]:
        """Determine which cognitive modules are required for a task."""
        required_modules = []
        
        task_type = task.task_type.lower()
        
        # Always include neurosymbolic core for reasoning
        required_modules.append(CognitiveModuleType.NEUROSYMBOLIC_CORE)
        
        # Memory requirements
        if 'remember' in task_type or 'recall' in task_type:
            required_modules.extend([
                CognitiveModuleType.WORKING_MEMORY,
                CognitiveModuleType.EPISODIC_MEMORY
            ])
        
        # Language processing
        if 'language' in task_type or 'text' in task_type:
            required_modules.append(CognitiveModuleType.TRANSFORMER_NLP)
        
        # Complex reasoning
        if 'reasoning' in task_type or 'problem' in task_type:
            required_modules.extend([
                CognitiveModuleType.METACOGNITIVE_MONITOR,
                CognitiveModuleType.WORKING_MEMORY
            ])
        
        # Creative tasks
        if 'creative' in task_type or 'innovative' in task_type:
            required_modules.extend([
                CognitiveModuleType.DIVERGENT_THINKING,
                CognitiveModuleType.ASSOCIATIVE_NETWORK
            ])
        
        return required_modules
    
    def _learn_from_task(self, task: CognitiveTask):
        """Learn from completed task to improve future performance."""
        
        if not task.result or task.error:
            return
        
        # Store episodic memory of the task
        if CognitiveModuleType.EPISODIC_MEMORY in self.cognitive_modules:
            episode_data = {
                'task_type': task.task_type,
                'input_summary': str(task.input_data)[:200],  # Truncated summary
                'result_summary': str(task.result)[:200],
                'processing_time': (task.completed - task.started).total_seconds(),
                'success': task.result.get('success', False),
                'modules_used': [m.value for m in task.required_modules],
                'context': task.context,
                'importance': 0.7 if task.result.get('success', False) else 0.4
            }
            
            memory_task = CognitiveTask(
                task_id=str(uuid.uuid4()),
                task_type='store_episode',
                input_data={'operation': 'store', 'episode': episode_data},
                priority=ProcessingPriority.LOW,
                required_modules=[CognitiveModuleType.EPISODIC_MEMORY]
            )
            
            self.cognitive_modules[CognitiveModuleType.EPISODIC_MEMORY].process(memory_task)
        
        # Update metacognitive monitoring
        if CognitiveModuleType.METACOGNITIVE_MONITOR in self.cognitive_modules:
            feedback = {
                'strategy_result': {
                    'problem_type': task.task_type,
                    'strategy': task.required_modules[0].value if task.required_modules else 'unknown',
                    'effectiveness': 1.0 if task.result.get('success', False) else 0.0
                }
            }
            
            self.cognitive_modules[CognitiveModuleType.METACOGNITIVE_MONITOR].update_state(feedback)
    
    def _update_performance_metrics(self, task: CognitiveTask, processing_time: float):
        """Update overall performance metrics."""
        self.performance_metrics['tasks_processed'] += 1
        
        # Update average processing time
        old_avg = self.performance_metrics['average_processing_time']
        n = self.performance_metrics['tasks_processed']
        self.performance_metrics['average_processing_time'] = (old_avg * (n-1) + processing_time) / n
        
        # Update success rate
        success = 1.0 if task.result and task.result.get('success', False) else 0.0
        old_success_rate = self.performance_metrics['success_rate']
        self.performance_metrics['success_rate'] = (old_success_rate * (n-1) + success) / n
    
    def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status."""
        module_statuses = {}
        for module_type, module in self.cognitive_modules.items():
            module_statuses[module_type.value] = module.get_status()
        
        return {
            "system_status": "active" if self.is_running else "idle",
            "performance_metrics": self.performance_metrics,
            "module_statuses": module_statuses,
            "task_queue_size": self.task_queue.qsize(),
            "executive_control_status": self.executive_control.get_status(),
            "timestamp": datetime.now().isoformat()
        }
    
    def demonstrate_enhanced_capabilities(self) -> Dict[str, Any]:
        """Demonstrate the enhanced cognitive architecture capabilities."""
        
        print("ðŸ§  Enhanced Cognitive Architecture Demonstration")
        print("=" * 65)
        
        # Test various cognitive capabilities
        test_scenarios = [
            {
                'name': 'Working Memory Processing',
                'task': CognitiveTask(
                    task_id='demo_working_memory',
                    task_type='memory_store_retrieve',
                    input_data={
                        'operation': 'store',
                        'item': {'concept': 'neural_symbolic_integration', 'importance': 0.9}
                    },
                    priority=ProcessingPriority.HIGH,
                    required_modules=[CognitiveModuleType.WORKING_MEMORY]
                )
            },
            {
                'name': 'Episodic Memory Formation',
                'task': CognitiveTask(
                    task_id='demo_episodic',
                    task_type='experience_storage',
                    input_data={
                        'operation': 'store',
                        'episode': {
                            'event': 'successful_problem_solving',
                            'context': {'domain': 'cognitive_architecture', 'difficulty': 'high'},
                            'emotional_valence': 0.8,
                            'importance': 0.9
                        }
                    },
                    priority=ProcessingPriority.MEDIUM,
                    required_modules=[CognitiveModuleType.EPISODIC_MEMORY]
                )
            },
            {
                'name': 'Metacognitive Monitoring',
                'task': CognitiveTask(
                    task_id='demo_metacognitive',
                    task_type='self_monitoring',
                    input_data={
                        'operation': 'monitor',
                        'system_state': {
                            'working_memory_load': 0.6,
                            'attention_focus': ['cognitive_architecture', 'demonstration'],
                            'processing_speed': 1.2,
                            'error_rate': 0.1,
                            'confidence_level': 0.8
                        }
                    },
                    priority=ProcessingPriority.HIGH,
                    required_modules=[CognitiveModuleType.METACOGNITIVE_MONITOR]
                )
            }
        ]
        
        results = {}
        
        for scenario in test_scenarios:
            print(f"\nðŸŽ¯ Testing: {scenario['name']}")
            result = self.process_cognitive_task(scenario['task'])
            results[scenario['name']] = result
            
            if result.get('success', False):
                print(f"   Result: âœ… SUCCESS")
            else:
                print(f"   Result: âŒ FAILED - {result.get('error', 'Unknown error')}")
        
        # Show system status
        print(f"\nðŸ“Š SYSTEM STATUS:")
        status = self.get_system_status()
        print(f"   Tasks Processed: {status['performance_metrics']['tasks_processed']}")
        print(f"   Success Rate: {status['performance_metrics']['success_rate']:.1%}")
        print(f"   Avg Processing Time: {status['performance_metrics']['average_processing_time']:.3f}s")
        print(f"   Active Modules: {len(status['module_statuses'])}")
        
        print(f"\nðŸŽ‰ ENHANCED COGNITIVE ARCHITECTURE DEMONSTRATION COMPLETE!")
        print("âœ… Multi-modal cognitive processing operational")
        print("âœ… Working memory with attention-based management")
        print("âœ… Episodic memory with temporal and contextual indexing")
        print("âœ… Metacognitive monitoring and self-awareness")
        print("âœ… Executive control coordination")
        print("âœ… Extensible architecture ready for additional modules")
        
        return {
            'demonstration_results': results,
            'system_status': status,
            'capabilities_validated': [
                'working_memory_management',
                'episodic_memory_formation',
                'metacognitive_monitoring',
                'executive_control',
                'modular_architecture',
                'performance_tracking'
            ]
        }


class ExecutiveController:
    """Executive control system for coordinating cognitive modules."""
    
    def __init__(self, cognitive_modules: Dict[CognitiveModuleType, CognitiveModule]):
        self.cognitive_modules = cognitive_modules
        self.coordination_history = deque(maxlen=50)
        self.resource_allocation = {}
        
    def coordinate_processing(self, task: CognitiveTask) -> Dict[str, Any]:
        """Coordinate processing across multiple cognitive modules."""
        
        coordination_id = str(uuid.uuid4())[:8]
        coordination_start = datetime.now()
        
        try:
            # Allocate resources
            self._allocate_resources(task.required_modules)
            
            # Process task through required modules
            module_results = {}
            
            for module_type in task.required_modules:
                if module_type in self.cognitive_modules:
                    module = self.cognitive_modules[module_type]
                    module_result = module.process(task)
                    module_results[module_type.value] = module_result
                else:
                    # Handle missing modules gracefully
                    module_results[module_type.value] = {
                        "error": f"Module {module_type.value} not available"
                    }
            
            # Integrate results
            integrated_result = self._integrate_module_results(module_results, task)
            
            # Record coordination
            coordination_record = {
                'coordination_id': coordination_id,
                'task_id': task.task_id,
                'modules_used': [m.value for m in task.required_modules],
                'processing_time': (datetime.now() - coordination_start).total_seconds(),
                'success': integrated_result.get('success', False),
                'timestamp': datetime.now()
            }
            
            self.coordination_history.append(coordination_record)
            
            return integrated_result
            
        except Exception as e:
            logger.error(f"Executive coordination error: {e}")
            return {"success": False, "error": f"Coordination failed: {str(e)}"}
    
    def _allocate_resources(self, required_modules: List[CognitiveModuleType]):
        """Allocate processing resources to required modules."""
        
        # Simple resource allocation - in practice this would be more sophisticated
        resource_per_module = 1.0 / len(required_modules) if required_modules else 1.0
        
        for module_type in required_modules:
            self.resource_allocation[module_type] = resource_per_module
    
    def _integrate_module_results(self, module_results: Dict[str, Dict[str, Any]], task: CognitiveTask) -> Dict[str, Any]:
        """Integrate results from multiple cognitive modules."""
        
        # Count successful modules
        successful_modules = sum(1 for result in module_results.values() 
                               if result.get('success', False))
        
        # If core neurosymbolic processing succeeded, use it as primary result
        if 'neurosymbolic_core' in module_results and module_results['neurosymbolic_core'].get('success', False):
            primary_result = module_results['neurosymbolic_core']
        else:
            # Find best available result
            primary_result = None
            for result in module_results.values():
                if result.get('success', False):
                    primary_result = result
                    break
            
            if not primary_result:
                primary_result = {"success": False, "error": "No modules produced successful results"}
        
        # Enhance with additional module outputs
        enhanced_result = primary_result.copy()
        enhanced_result['module_contributions'] = module_results
        enhanced_result['coordination_success_rate'] = successful_modules / len(module_results) if module_results else 0.0
        
        return enhanced_result
    
    def get_status(self) -> Dict[str, Any]:
        """Get executive controller status."""
        
        recent_coordinations = list(self.coordination_history)[-10:]  # Last 10
        
        if recent_coordinations:
            avg_processing_time = statistics.mean([c['processing_time'] for c in recent_coordinations])
            success_rate = sum(1 for c in recent_coordinations if c['success']) / len(recent_coordinations)
        else:
            avg_processing_time = 0.0
            success_rate = 0.0
        
        return {
            'total_coordinations': len(self.coordination_history),
            'recent_success_rate': success_rate,
            'average_processing_time': avg_processing_time,
            'active_resource_allocations': len(self.resource_allocation),
            'last_coordination': recent_coordinations[-1]['timestamp'].isoformat() if recent_coordinations else None
        }


def demonstrate_enhanced_cognitive_architecture():
    """Demonstrate the enhanced cognitive architecture with comprehensive capabilities."""
    
    try:
        # Initialize the enhanced cognitive architecture
        if INTEGRATION_AVAILABLE:
            neural_symbolic_system = NeuralSymbolicIntegration()
            architecture = EnhancedCognitiveArchitecture(neural_symbolic_system=neural_symbolic_system)
        else:
            architecture = EnhancedCognitiveArchitecture()
        
        # Run comprehensive demonstration
        results = architecture.demonstrate_enhanced_capabilities()
        
        return architecture, results
        
    except Exception as e:
        logger.error(f"Demonstration failed: {e}")
        print(f"âŒ Demonstration failed: {e}")
        return None, None


if __name__ == "__main__":
    demonstrate_enhanced_cognitive_architecture()
